# üìä Previs√£o de Diabetes na AWS com [SageMaker Canvas](https://aws.amazon.com/pt/sagemaker/canvas/)

O meu projeto foi para prever diabetes de pacientes, usei a a base de dados que a AWS fornece e meus resultados foram bem satisfat√≥rios.

<img src="OK.jpg">

# üëâ Resumo dos Resultados do Modelo de Previs√£o de Diabetes
## 1. Acur√°cia (Accuracy)
*Valor: 81.138%*

Descri√ß√£o: A acur√°cia √© a propor√ß√£o de todas as previs√µes corretas (tanto positivas quanto negativas) em rela√ß√£o ao total de casos. Com uma acur√°cia de 81.138%, o modelo est√° corretamente prevendo a presen√ßa ou aus√™ncia de diabetes em aproximadamente 81% dos casos.
## 2. F1-Score
*Valor: 0.618 (ou 61.8%)*

Descri√ß√£o: O F1-Score √© a m√©dia harm√¥nica da precis√£o e recall, fornecendo uma √∫nica m√©trica para avaliar a performance do modelo com um equil√≠brio entre precis√£o e recall. Com um F1-Score de 0.618, o modelo mostra um desempenho razo√°vel em prever corretamente os casos positivos de diabetes.
## 3. Precis√£o (Precision)
*Valor: 52.041%*

Descri√ß√£o: A precis√£o √© a propor√ß√£o de verdadeiros positivos em rela√ß√£o ao total de positivos previstos (TP / (TP + FP)). Com uma precis√£o de 52.041%, o modelo indica que quando ele prev√™ diabetes, est√° correto em 52% das vezes.
## 4. Recall (Recall)
*Valor: 76.119%*

Descri√ß√£o: O recall √© a propor√ß√£o de verdadeiros positivos em rela√ß√£o ao total de positivos reais (TP / (TP + FN)). Com um recall de 76.119%, o modelo √© capaz de identificar 76% dos casos de diabetes presentes no conjunto de dados.
## 5. AUC-ROC
*Valor: 0.847*

Descri√ß√£o: A AUC-ROC (√Årea sob a Curva da Caracter√≠stica de Opera√ß√£o do Receptor) mede a capacidade do modelo de distinguir entre classes. Com uma AUC-ROC de 0.847, o modelo tem uma excelente capacidade de diferenciar entre pacientes com e sem diabetes.
Matriz de Confus√£o
Predicted / Actual	0	1
0	220 (TN)	16 (FN)
1	47 (FP)	51 (TP)
Interpreta√ß√£o dos Resultados da Matriz de Confus√£o
True Positive (TP):

### *Valor: 51 (15.3% dos resultados previstos)*

Descri√ß√£o: Casos onde o modelo previu corretamente a presen√ßa de diabetes.
False Negative (FN):

### *Valor: 16 (4.8% dos resultados previstos)*

Descri√ß√£o: Casos onde o modelo falhou ao prever a presen√ßa de diabetes, mas o paciente realmente tem diabetes.
False Positive (FP):

### *Valor: 47 (14.1% dos resultados previstos)*

Descri√ß√£o: Casos onde o modelo previu diabetes erroneamente, mas o paciente n√£o tem diabetes.
True Negative (TN):

### *Valor: 220 (65.9% dos resultados previstos)*

Descri√ß√£o: Casos onde o modelo previu corretamente a aus√™ncia de diabetes.

# Conclus√£o üìä
Meu modelo de Machine Learning para previs√£o de diabetes apresentou uma boa acur√°cia de 81.138% e um AUC-ROC de 0.847, indicando uma boa capacidade de distin√ß√£o entre pacientes com e sem diabetes. No entanto, a precis√£o de 52.041% sugere que h√° um n√∫mero significativo de falsos positivos, enquanto o recall de 76.119% indica que o modelo est√° bem em identificar casos de diabetes. O F1-Score de 0.618 fornece uma vis√£o equilibrada do desempenho geral do modelo.
